{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a49771f3",
   "metadata": {},
   "source": [
    "\n",
    "# Ejemplo RAG Simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "8d02b36e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from docling.document_converter import DocumentConverter\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "from gensim.models import Word2Vec\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter, MarkdownHeaderTextSplitter\n",
    "\n",
    "import os\n",
    "import google.generativeai as genai\n",
    "\n",
    "\n",
    "load_dotenv(\"../.env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3d8935",
   "metadata": {},
   "source": [
    "## Extraccion de Texto - OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "580ed59e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-21 19:40:37,888 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-21 19:40:38,093 - INFO - Going to convert document batch...\n",
      "2025-10-21 19:40:38,096 - INFO - Initializing pipeline for StandardPdfPipeline with options hash 4f2edc0f7d9bb60b38ebfecf9a2609f5\n",
      "2025-10-21 19:40:38,145 - INFO - Loading plugin 'docling_defaults'\n",
      "2025-10-21 19:40:38,156 - INFO - Registered picture descriptions: ['vlm', 'api']\n",
      "2025-10-21 19:40:38,213 - INFO - Loading plugin 'docling_defaults'\n",
      "2025-10-21 19:40:38,232 - INFO - Registered ocr engines: ['auto', 'easyocr', 'ocrmac', 'rapidocr', 'tesserocr', 'tesseract']\n",
      "2025-10-21 19:40:38,236 - INFO - rapidocr cannot be used because onnxruntime is not installed.\n",
      "2025-10-21 19:40:38,241 - INFO - easyocr cannot be used because it is not installed.\n",
      "2025-10-21 19:40:39,491 - INFO - Accelerator device: 'cpu'\n",
      "\u001b[32m[INFO] 2025-10-21 19:40:39,546 [RapidOCR] base.py:22: Using engine_name: torch\u001b[0m\n",
      "\u001b[32m[INFO] 2025-10-21 19:40:39,689 [RapidOCR] download_file.py:60: File exists and is valid: /home/keras/wordspaces/ml2_clases/.venv/lib/python3.12/site-packages/rapidocr/models/ch_PP-OCRv4_det_infer.pth\u001b[0m\n",
      "\u001b[32m[INFO] 2025-10-21 19:40:39,694 [RapidOCR] torch.py:54: Using /home/keras/wordspaces/ml2_clases/.venv/lib/python3.12/site-packages/rapidocr/models/ch_PP-OCRv4_det_infer.pth\u001b[0m\n",
      "\u001b[32m[INFO] 2025-10-21 19:40:40,655 [RapidOCR] base.py:22: Using engine_name: torch\u001b[0m\n",
      "\u001b[32m[INFO] 2025-10-21 19:40:40,661 [RapidOCR] download_file.py:60: File exists and is valid: /home/keras/wordspaces/ml2_clases/.venv/lib/python3.12/site-packages/rapidocr/models/ch_ptocr_mobile_v2.0_cls_infer.pth\u001b[0m\n",
      "\u001b[32m[INFO] 2025-10-21 19:40:40,663 [RapidOCR] torch.py:54: Using /home/keras/wordspaces/ml2_clases/.venv/lib/python3.12/site-packages/rapidocr/models/ch_ptocr_mobile_v2.0_cls_infer.pth\u001b[0m\n",
      "\u001b[32m[INFO] 2025-10-21 19:40:40,830 [RapidOCR] base.py:22: Using engine_name: torch\u001b[0m\n",
      "\u001b[32m[INFO] 2025-10-21 19:40:40,931 [RapidOCR] download_file.py:60: File exists and is valid: /home/keras/wordspaces/ml2_clases/.venv/lib/python3.12/site-packages/rapidocr/models/ch_PP-OCRv4_rec_infer.pth\u001b[0m\n",
      "\u001b[32m[INFO] 2025-10-21 19:40:40,934 [RapidOCR] torch.py:54: Using /home/keras/wordspaces/ml2_clases/.venv/lib/python3.12/site-packages/rapidocr/models/ch_PP-OCRv4_rec_infer.pth\u001b[0m\n",
      "2025-10-21 19:40:41,402 - INFO - Auto OCR model selected rapidocr with torch.\n",
      "2025-10-21 19:40:41,417 - INFO - Accelerator device: 'cpu'\n",
      "2025-10-21 19:40:44,802 - INFO - Accelerator device: 'cpu'\n",
      "2025-10-21 19:40:46,129 - INFO - Processing document Proyecto Final - Curso MLE2.pdf\n",
      "2025-10-21 19:41:03,158 - INFO - Finished converting document Proyecto Final - Curso MLE2.pdf in 26.97 sec.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!-- image -->\n",
      "\n",
      "Science\n",
      "\n",
      "## Proyecto Curso II -Especialización Machine Learning Engineering\n",
      "\n",
      "El proyecto del curso II de la especialización de Machine Learning Engineering tiene como objetivo enfrentar al estudiante a:\n",
      "\n",
      "- -Conocimiento  teórico  de  algoritmos  populares  y  avanzados  de  Machine Learning en la industria\n",
      "- -Administración de ciclo de vida de modelos de Machine Learning\n",
      "1.  README.md\n",
      "- a.  Problema de ML\n",
      "- b.  Diagrama de flujo del proyecto\n",
      "- c. Descripción del dataset con su respectivo diccionario de datos\n",
      "- d.  Model Card https://www.kaggle.com/code/var0101/model-cards\n",
      "- e.  Resultados con Métricas de evaluación offline y online\n",
      "- f. Conclusiones\n",
      "2.  Estructura del repositorio de código con:\n",
      "- a.  Carpeta de notebooks\n",
      "- i.  Notebook preprocesamiento de datos\n",
      "- ii.  Notebook de Machine Learning\n",
      "- b.  Carpeta de datos (.csv, .txt, .parquet)\n",
      "- c.  Módulo de código reusable\n",
      "- d.  Scripts de ejecución (Preprocesamiento, entrenamiento y predicción)\n",
      "3.  Link con evidencia de experimentos realizados en MLflow con sus respectivo artefactos y un modelo productivo (e.g. https://dagshub.com/abdala9512/fake-news-poc/experiments)\n",
      "- a.  Se espera de los experimentos tener métricas , parámetros y artefactos en ellos.\n",
      "4.  Release de la versión 1.0.0** con sus respectivas notas https://docs.github.com/es/repositories/releasing-projects-on-github/managing -releases-in-a-repository\n",
      "5.  Ramas Main y Development (al menos una pull request cerrada exitosamente)\n",
      "6.  Documentación sobre la estrategia de git utilizada\n",
      "7.  [OPCIONAL] Otros (.gitignore, requirements.txt, instrucciones de ejecución )\n",
      "\n",
      "Fecha máxima de entrega: Domingo 24 de Agosto de 2025\n",
      "\n",
      "Entregable : Repositorio de GitHub en versión 1.0.0** con las siguientes secciones:\n",
      "\n",
      "<!-- image -->\n",
      "\n",
      "<!-- image -->\n",
      "\n",
      "## Indicaciones Generales del proyecto\n",
      "\n",
      "1.  El conjunto de datos es de libre elección.   Se sugiere utilizar las siguientes fuentes para seleccionar un conjunto de datos:\n",
      "- a.  Kaggle https://www.kaggle.com/datasets\n",
      "- b.  Google Datasets https://datasetsearch.research.google.com/\n",
      "- c. UCI datasets https://archive.ics.uci.edu/datasets\n",
      "2.  Definir el problema de Machine Learning que se quiere resolver (Supervisado,  no  supervisado)  y  el  subconjunto  de  problemas  (Regresión, clasificación, Clustering, Reducción de dimensiones).\n",
      "\n",
      "## Sugerencias para el proyecto\n",
      "\n",
      "- -Para los experimentos de MLflow, se recomienda revisar esta excelente guía de métricas de ML https://arize.com/blog-course/model-evaluation-metrics/\n",
      "- -Usar datasets tabulares de  tamaño  no  mayor  a  100MB,  además  se recomienda  no  usar  datos  que  requieran  procesos  de  ingeniería  de  datos complejos, pues esto no será evaluado.\n",
      "- -Crear estructura del proyecto con cookiecutter  https://www.cookiecutter.io/\n",
      "- -Revisar la guía básica de Markdown para preparar el README.md con mejor estructura. https://markdown.es/\n",
      "- -Agregar  excepciones  adicionales  para  archivos  que  estemos  manejando. https://docs.github.com/es/get-started/git-basics/ignoring-files\n",
      "- -Usar. gitkeep en carpetas provisionales del proyecto (data, tmp, etc).\n",
      "- -Para  los Pull Request, documentarlos acorde a los cambios y usar git  and merge para  fusionarlo  con  la  rama  main.  (Se  recomienda  github  Flow https://docs.github.com/es/get-started/using-github/github-flow)\n",
      "\n",
      "<!-- image -->\n",
      "\n",
      "## Evaluación\n",
      "\n",
      "| Componente                     | Tipo        | Descripción                                                                                                                                                                                                                                                               | Porcentaje en la evaluación                                  |\n",
      "|--------------------------------|-------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------|\n",
      "| Repositorio de Github          | Obligatorio | El estudiante presenta su proyecto de acuerdo con la estructura definida por el profesor.                                                                                                                                                                                 | 25%                                                          |\n",
      "| Modelo de Machine Learning     | Obligatorio | El estudiante documenta y desarrolla un modelo de machine learning alineado con sus hipótesis, además de evaluarlo con métricas que tengan sentido para el problema que previamente escogió y usando mlflow como herramienta de administración de modelos y experimentos. | 50%                                                          |\n",
      "| Buenas prácticas de desarrollo | Obligatorio | El estudiante sigue el proceso estándar de desarrollo basado en control de versiones, usando commits, pull requests y releases en su proyecto.                                                                                                                            | 15%                                                          |\n",
      "| Documentación                  | Obligatorio | El estudiante documenta el repositorio con archivos tipo markdown, o jupyter notebooks, así como también el código generado con docstrings, naming conventions, etc.                                                                                                      | 10%                                                          |\n",
      "| Reto ML 1                      | Opcional    | El estudiante demuestra dominio de los algoritmos vistos en clase realizando experimentos con más de uno y obteniendo resultados excepcionales (estos dependerán e tipo de problema que se busque resolver)                                                               | 10% [Acumulable para todos los cursos de la especialización] |\n",
      "| Reto ML2                       | Opcional    | El estudiante hace uso del feature store para almacenar y servir carateristicas para modelos de machine learning. (Recomendado usar Feast, que fue la herramienta vista en calse)                                                                                         | 10% [Acumulable para todos los cursos de la especialización] |\n",
      "\n",
      "## Instrucciones de Envío\n",
      "\n",
      "En el classroom del curso se habilitará una tarea donde se debe colocar el enlace del  repositorio  de  github  con la estructura previamente definida (Para la fecha de entrega final no debe haber ningún commit adicional y el repositorio debe estar en la versión 1.0.0**).\n",
      "\n",
      "NOTA: El  enlace  del  repositorio  lo  pueden  compartir  desde  su  creación, El entregable se evaluará con el último commit del 24 de Agosto de 2025.\n",
      "\n",
      "**En  caso  de  querer  usar  el  mismo  proyecto y repositorio del curso 1 de la especialización, crear una versión 2.0.0 en GitHub\n",
      "\n",
      "En caso de dudas adicionales estas serán atendidas por los canales de comunicación habituales.\n"
     ]
    }
   ],
   "source": [
    "source = \"../docs/Proyecto Final - Curso MLE2.pdf\"  # PDF path or URL\n",
    "converter = DocumentConverter()\n",
    "result = converter.convert(source)\n",
    "print(result.document.export_to_markdown())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ed54a2",
   "metadata": {},
   "source": [
    "## Chunking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7e13ad",
   "metadata": {},
   "source": [
    "#### Metodo 1 de Chunking -> Chunking de Tamaño Fijo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "fd4beb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixed_window_splitter(text: str, chunk_size: int = 500, chunk_overlap: int = 0) -> list[str]:\n",
    "    \"\"\"Corta el texto en pedazos de tamaño fijo.\"\"\"\n",
    "    if chunk_overlap >= chunk_size:\n",
    "        raise ValueError(\"El solapamiento (overlap) no puede ser mayor o igual al tamaño del chunk.\")\n",
    "        \n",
    "    chunks = []\n",
    "    start = 0\n",
    "    while start < len(text):\n",
    "        end = start + chunk_size\n",
    "        chunks.append(text[start:end])\n",
    "        start += chunk_size - chunk_overlap\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074a5202",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts= fixed_window_splitter(result.document.export_to_markdown(), chunk_size=500, chunk_overlap=50)\n",
    "print(\"\\n--- Método 1: Tamaño Fijo ---\", len(texts))\n",
    "\n",
    "for i, chunk in enumerate(texts):\n",
    "    print(f\"Chunk {i+1}: '{chunk}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e00ad84",
   "metadata": {},
   "source": [
    "#### Metodo 2 de Chunking -> Chunking Recursivo por Caracteres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "1675ba6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recursive_character_splitter(text: str, chunk_size: int = 500, chunk_overlap: int = 50) -> list[str]:\n",
    "    \"\"\"Corta el texto usando un enfoque recursivo basado en separadores.\"\"\"\n",
    "    text_splitter_recursive = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap\n",
    "    )\n",
    "\n",
    "    return text_splitter_recursive.split_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "0aff4190",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Método 2: Recursivo por Caracteres --- 21\n",
      "Chunk 1: '<!-- image -->\n",
      "\n",
      "Science\n",
      "\n",
      "## Proyecto Curso II -Especialización Machine Learning Engineering\n",
      "\n",
      "El proyecto del curso II de la especialización de Machine Learning Engineering tiene como objetivo enfrentar al estudiante a:'\n",
      "--------------------\n",
      "Chunk 2: '- -Conocimiento  teórico  de  algoritmos  populares  y  avanzados  de  Machine Learning en la industria\n",
      "- -Administración de ciclo de vida de modelos de Machine Learning\n",
      "1.  README.md\n",
      "- a.  Problema de ML\n",
      "- b.  Diagrama de flujo del proyecto\n",
      "- c. Descripción del dataset con su respectivo diccionario de datos\n",
      "- d.  Model Card https://www.kaggle.com/code/var0101/model-cards\n",
      "- e.  Resultados con Métricas de evaluación offline y online\n",
      "- f. Conclusiones'\n",
      "--------------------\n",
      "Chunk 3: '- f. Conclusiones\n",
      "2.  Estructura del repositorio de código con:\n",
      "- a.  Carpeta de notebooks\n",
      "- i.  Notebook preprocesamiento de datos\n",
      "- ii.  Notebook de Machine Learning\n",
      "- b.  Carpeta de datos (.csv, .txt, .parquet)\n",
      "- c.  Módulo de código reusable\n",
      "- d.  Scripts de ejecución (Preprocesamiento, entrenamiento y predicción)\n",
      "3.  Link con evidencia de experimentos realizados en MLflow con sus respectivo artefactos y un modelo productivo (e.g. https://dagshub.com/abdala9512/fake-news-poc/experiments)'\n",
      "--------------------\n",
      "Chunk 4: '- a.  Se espera de los experimentos tener métricas , parámetros y artefactos en ellos.\n",
      "4.  Release de la versión 1.0.0** con sus respectivas notas https://docs.github.com/es/repositories/releasing-projects-on-github/managing -releases-in-a-repository\n",
      "5.  Ramas Main y Development (al menos una pull request cerrada exitosamente)\n",
      "6.  Documentación sobre la estrategia de git utilizada\n",
      "7.  [OPCIONAL] Otros (.gitignore, requirements.txt, instrucciones de ejecución )'\n",
      "--------------------\n",
      "Chunk 5: 'Fecha máxima de entrega: Domingo 24 de Agosto de 2025\n",
      "\n",
      "Entregable : Repositorio de GitHub en versión 1.0.0** con las siguientes secciones:\n",
      "\n",
      "<!-- image -->\n",
      "\n",
      "<!-- image -->\n",
      "\n",
      "## Indicaciones Generales del proyecto'\n",
      "--------------------\n",
      "Chunk 6: '1.  El conjunto de datos es de libre elección.   Se sugiere utilizar las siguientes fuentes para seleccionar un conjunto de datos:\n",
      "- a.  Kaggle https://www.kaggle.com/datasets\n",
      "- b.  Google Datasets https://datasetsearch.research.google.com/\n",
      "- c. UCI datasets https://archive.ics.uci.edu/datasets\n",
      "2.  Definir el problema de Machine Learning que se quiere resolver (Supervisado,  no  supervisado)  y  el  subconjunto  de  problemas  (Regresión, clasificación, Clustering, Reducción de dimensiones).'\n",
      "--------------------\n",
      "Chunk 7: '## Sugerencias para el proyecto'\n",
      "--------------------\n",
      "Chunk 8: '- -Para los experimentos de MLflow, se recomienda revisar esta excelente guía de métricas de ML https://arize.com/blog-course/model-evaluation-metrics/\n",
      "- -Usar datasets tabulares de  tamaño  no  mayor  a  100MB,  además  se recomienda  no  usar  datos  que  requieran  procesos  de  ingeniería  de  datos complejos, pues esto no será evaluado.\n",
      "- -Crear estructura del proyecto con cookiecutter  https://www.cookiecutter.io/'\n",
      "--------------------\n",
      "Chunk 9: '- -Revisar la guía básica de Markdown para preparar el README.md con mejor estructura. https://markdown.es/\n",
      "- -Agregar  excepciones  adicionales  para  archivos  que  estemos  manejando. https://docs.github.com/es/get-started/git-basics/ignoring-files\n",
      "- -Usar. gitkeep en carpetas provisionales del proyecto (data, tmp, etc).'\n",
      "--------------------\n",
      "Chunk 10: '- -Para  los Pull Request, documentarlos acorde a los cambios y usar git  and merge para  fusionarlo  con  la  rama  main.  (Se  recomienda  github  Flow https://docs.github.com/es/get-started/using-github/github-flow)'\n",
      "--------------------\n",
      "Chunk 11: '<!-- image -->\n",
      "\n",
      "## Evaluación'\n",
      "--------------------\n",
      "Chunk 12: '| Componente                     | Tipo        | Descripción                                                                                                                                                                                                                                                               | Porcentaje en la evaluación                                  |'\n",
      "--------------------\n",
      "Chunk 13: '|--------------------------------|-------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------|'\n",
      "--------------------\n",
      "Chunk 14: '| Repositorio de Github          | Obligatorio | El estudiante presenta su proyecto de acuerdo con la estructura definida por el profesor.                                                                                                                                                                                 | 25%                                                          |'\n",
      "--------------------\n",
      "Chunk 15: '| Modelo de Machine Learning     | Obligatorio | El estudiante documenta y desarrolla un modelo de machine learning alineado con sus hipótesis, además de evaluarlo con métricas que tengan sentido para el problema que previamente escogió y usando mlflow como herramienta de administración de modelos y experimentos. | 50%                                                          |'\n",
      "--------------------\n",
      "Chunk 16: '| Buenas prácticas de desarrollo | Obligatorio | El estudiante sigue el proceso estándar de desarrollo basado en control de versiones, usando commits, pull requests y releases en su proyecto.                                                                                                                            | 15%                                                          |'\n",
      "--------------------\n",
      "Chunk 17: '| Documentación                  | Obligatorio | El estudiante documenta el repositorio con archivos tipo markdown, o jupyter notebooks, así como también el código generado con docstrings, naming conventions, etc.                                                                                                      | 10%                                                          |'\n",
      "--------------------\n",
      "Chunk 18: '| Reto ML 1                      | Opcional    | El estudiante demuestra dominio de los algoritmos vistos en clase realizando experimentos con más de uno y obteniendo resultados excepcionales (estos dependerán e tipo de problema que se busque resolver)                                                               | 10% [Acumulable para todos los cursos de la especialización] |'\n",
      "--------------------\n",
      "Chunk 19: '| Reto ML2                       | Opcional    | El estudiante hace uso del feature store para almacenar y servir carateristicas para modelos de machine learning. (Recomendado usar Feast, que fue la herramienta vista en calse)                                                                                         | 10% [Acumulable para todos los cursos de la especialización] |'\n",
      "--------------------\n",
      "Chunk 20: '## Instrucciones de Envío\n",
      "\n",
      "En el classroom del curso se habilitará una tarea donde se debe colocar el enlace del  repositorio  de  github  con la estructura previamente definida (Para la fecha de entrega final no debe haber ningún commit adicional y el repositorio debe estar en la versión 1.0.0**).\n",
      "\n",
      "NOTA: El  enlace  del  repositorio  lo  pueden  compartir  desde  su  creación, El entregable se evaluará con el último commit del 24 de Agosto de 2025.'\n",
      "--------------------\n",
      "Chunk 21: '**En  caso  de  querer  usar  el  mismo  proyecto y repositorio del curso 1 de la especialización, crear una versión 2.0.0 en GitHub\n",
      "\n",
      "En caso de dudas adicionales estas serán atendidas por los canales de comunicación habituales.'\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "texts = recursive_character_splitter(result.document.export_to_markdown(), chunk_size=500, chunk_overlap=50)\n",
    "\n",
    "print(\"\\n--- Método 2: Recursivo por Caracteres ---\", len(texts))\n",
    "\n",
    "for i, chunk in enumerate(texts):\n",
    "    print(f\"Chunk {i+1}: '{chunk}'\")\n",
    "    print(\"-\"*20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155af51a",
   "metadata": {},
   "source": [
    "#### Metodo 3 de Chunking -> Chunking Consciente del Contenido (Markdown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "298f3ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def markdown_header_splitter(text: str) -> list[str]:\n",
    "    \"\"\"Corta el texto usando encabezados de Markdown como separadores.\"\"\"\n",
    "    # 1. Define por qué encabezados quieres dividir el texto\n",
    "    headers_to_split_on = [\n",
    "        (\"#\", \"Header 1\"),\n",
    "        (\"##\", \"Header 2\"),\n",
    "        (\"###\", \"Header 3\"),\n",
    "    ]\n",
    "\n",
    "    # 2. Configura el divisor de Markdown\n",
    "    markdown_splitter = MarkdownHeaderTextSplitter(headers_to_split_on=headers_to_split_on)\n",
    "\n",
    "    # Esto devuelve la lista de objetos Document\n",
    "    chunks_with_metadata = markdown_splitter.split_text(text)\n",
    "\n",
    "    # Extraemos solo el .page_content de cada chunk\n",
    "    text_only_chunks = [chunk.page_content for chunk in chunks_with_metadata]\n",
    "\n",
    "    return text_only_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969f0662",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = markdown_header_splitter(result.document.export_to_markdown())\n",
    "\n",
    "print(\"\\n--- Método 3: Consciente del Contenido (Markdown) ---\", len(texts))\n",
    "\n",
    "for i, chunk in enumerate(texts):\n",
    "    print(f\"Chunk {i+1}: '{chunk}'\")\n",
    "    print(\"-\"*20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f44a320",
   "metadata": {},
   "source": [
    "## Pregunta RAG: QUESTION = '¿Cuáles son los criterios de evaluación?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "5b145f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUESTION = '¿Cuáles son los criterios de evaluación?'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8e751f",
   "metadata": {},
   "source": [
    "### Word2Vec Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1c696db4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/keras/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/keras/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/keras/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from gensim.utils import simple_preprocess\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Descargar recursos de NLTK si es la primera vez\n",
    "nltk.download('punkt')  #Tokenizador\n",
    "nltk.download('stopwords') #Stopwords\n",
    "nltk.download('punkt_tab') #Tokenizador para tablas\n",
    "\n",
    "# Lista de stopwords en español\n",
    "stop_words = set(stopwords.words('spanish'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "1932f344",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text_spanish(text):\n",
    "    # Paso 1: dividir en oraciones\n",
    "    sentences = sent_tokenize(text, language='spanish')\n",
    "    \n",
    "    # Paso 2: tokenizar oraciones y limpiar\n",
    "    tokenized_sentences = []\n",
    "    for sentence in sentences:\n",
    "        tokens = simple_preprocess(sentence, deacc=True)  # deacc=True quita tildes y convierte a minúsculas\n",
    "        # La divide en una lista de palabras individuales (tokens)\n",
    "        # Elimina la puntuación y convierte a minúsculas\n",
    "\n",
    "        filtered = [word for word in tokens if word not in stop_words and len(word) > 2] # Elimina stopwords y palabras muy cortas\n",
    "        tokenized_sentences.append(filtered)\n",
    "        \n",
    "    return tokenized_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "5bb1c37a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['image', 'science', 'proyecto', 'curso', 'especializacion', 'machine', 'learning', 'engineering', 'proyecto', 'curso', 'especializacion', 'machine', 'learning', 'engineering', 'objetivo', 'enfrentar', 'estudiante', 'conocimiento', 'teorico', 'algoritmos', 'populares', 'avanzados', 'machine', 'learning', 'industria', 'administracion', 'ciclo', 'vida', 'modelos', 'machine', 'learning']]\n"
     ]
    }
   ],
   "source": [
    "tokens = preprocess_text_spanish(result.document.export_to_markdown())\n",
    "print(tokens[:1])  # Mostrar las primeras 3 oraciones tokenizadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "99bcb142",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 14:39:51,979 - INFO - collecting all words and their counts\n",
      "2025-10-22 14:39:51,981 - INFO - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2025-10-22 14:39:51,982 - INFO - collected 280 word types from a corpus of 473 raw words and 30 sentences\n",
      "2025-10-22 14:39:51,983 - INFO - Creating a fresh vocabulary\n",
      "2025-10-22 14:39:51,985 - INFO - Word2Vec lifecycle event {'msg': 'effective_min_count=1 retains 280 unique words (100.00% of original 280, drops 0)', 'datetime': '2025-10-22T14:39:51.985158', 'gensim': '4.4.0', 'python': '3.12.10 (main, Sep 30 2025, 03:55:04) [GCC 11.4.0]', 'platform': 'Linux-6.6.87.2-microsoft-standard-WSL2-x86_64-with-glibc2.35', 'event': 'prepare_vocab'}\n",
      "2025-10-22 14:39:51,986 - INFO - Word2Vec lifecycle event {'msg': 'effective_min_count=1 leaves 473 word corpus (100.00% of original 473, drops 0)', 'datetime': '2025-10-22T14:39:51.986105', 'gensim': '4.4.0', 'python': '3.12.10 (main, Sep 30 2025, 03:55:04) [GCC 11.4.0]', 'platform': 'Linux-6.6.87.2-microsoft-standard-WSL2-x86_64-with-glibc2.35', 'event': 'prepare_vocab'}\n",
      "2025-10-22 14:39:51,987 - INFO - deleting the raw counts dictionary of 280 items\n",
      "2025-10-22 14:39:51,988 - INFO - sample=0.001 downsamples 87 most-common words\n",
      "2025-10-22 14:39:51,989 - INFO - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 337.2965404006047 word corpus (71.3%% of prior 473)', 'datetime': '2025-10-22T14:39:51.989773', 'gensim': '4.4.0', 'python': '3.12.10 (main, Sep 30 2025, 03:55:04) [GCC 11.4.0]', 'platform': 'Linux-6.6.87.2-microsoft-standard-WSL2-x86_64-with-glibc2.35', 'event': 'prepare_vocab'}\n",
      "2025-10-22 14:39:51,992 - INFO - estimated required memory for 280 words and 60 dimensions: 274400 bytes\n",
      "2025-10-22 14:39:51,993 - INFO - resetting layer weights\n",
      "2025-10-22 14:39:51,996 - INFO - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2025-10-22T14:39:51.996793', 'gensim': '4.4.0', 'python': '3.12.10 (main, Sep 30 2025, 03:55:04) [GCC 11.4.0]', 'platform': 'Linux-6.6.87.2-microsoft-standard-WSL2-x86_64-with-glibc2.35', 'event': 'build_vocab'}\n",
      "2025-10-22 14:39:51,997 - INFO - Word2Vec lifecycle event {'msg': 'training model with 3 workers on 280 vocabulary and 60 features, using sg=1 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2025-10-22T14:39:51.997752', 'gensim': '4.4.0', 'python': '3.12.10 (main, Sep 30 2025, 03:55:04) [GCC 11.4.0]', 'platform': 'Linux-6.6.87.2-microsoft-standard-WSL2-x86_64-with-glibc2.35', 'event': 'train'}\n",
      "2025-10-22 14:39:52,002 - INFO - EPOCH 0: training on 473 raw words (335 effective words) took 0.0s, 246350 effective words/s\n",
      "2025-10-22 14:39:52,006 - INFO - EPOCH 1: training on 473 raw words (343 effective words) took 0.0s, 256605 effective words/s\n",
      "2025-10-22 14:39:52,010 - INFO - EPOCH 2: training on 473 raw words (347 effective words) took 0.0s, 237911 effective words/s\n",
      "2025-10-22 14:39:52,014 - INFO - EPOCH 3: training on 473 raw words (336 effective words) took 0.0s, 266937 effective words/s\n",
      "2025-10-22 14:39:52,017 - INFO - EPOCH 4: training on 473 raw words (339 effective words) took 0.0s, 271876 effective words/s\n",
      "2025-10-22 14:39:52,018 - INFO - Word2Vec lifecycle event {'msg': 'training on 2365 raw words (1700 effective words) took 0.0s, 85245 effective words/s', 'datetime': '2025-10-22T14:39:52.018305', 'gensim': '4.4.0', 'python': '3.12.10 (main, Sep 30 2025, 03:55:04) [GCC 11.4.0]', 'platform': 'Linux-6.6.87.2-microsoft-standard-WSL2-x86_64-with-glibc2.35', 'event': 'train'}\n",
      "2025-10-22 14:39:52,018 - INFO - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=280, vector_size=60, alpha=0.025>', 'datetime': '2025-10-22T14:39:52.018905', 'gensim': '4.4.0', 'python': '3.12.10 (main, Sep 30 2025, 03:55:04) [GCC 11.4.0]', 'platform': 'Linux-6.6.87.2-microsoft-standard-WSL2-x86_64-with-glibc2.35', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "modelo = Word2Vec(\n",
    "    tokens, \n",
    "    vector_size=60, # Dimensionalidad del espacio vectorial\n",
    "    window=5, #Es el tamaño de la ventana de contexto. Para aprender el significado de una palabra, el modelo mirará las 5 palabras que la preceden y las 5 que la siguen\n",
    "    min_count=1, # Mínimo número de ocurrencias para considerar una palabra\n",
    "    sg=1 # Usar Skip-gram (sg=1) en lugar de CBOW (sg=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "d5974830",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.01344557, -0.00131021,  0.00295761,  0.01248962, -0.0039169 ,\n",
       "       -0.00389292,  0.0170833 ,  0.00108022, -0.00367756,  0.01471856,\n",
       "        0.00575105, -0.00885321,  0.01134294,  0.0071739 , -0.01139473,\n",
       "       -0.00119772,  0.002078  ,  0.00909631, -0.00383826, -0.00534405,\n",
       "        0.00314703,  0.00078638,  0.00241346, -0.00394885, -0.00993309,\n",
       "        0.01198021,  0.01226117,  0.01406053, -0.01477605,  0.00430212,\n",
       "       -0.00594526,  0.01488244,  0.00541708,  0.00799153,  0.00541288,\n",
       "        0.01223443, -0.0103472 ,  0.01220585, -0.00533314, -0.00715146,\n",
       "       -0.00370761,  0.01657126, -0.01154723, -0.00371517,  0.01151392,\n",
       "       -0.00011743, -0.01071196, -0.01058971,  0.01458341,  0.01167425,\n",
       "        0.00826388, -0.00568103, -0.01513977,  0.0073448 ,  0.01254901,\n",
       "       -0.00877339, -0.01302378, -0.00525597, -0.0072409 , -0.004888  ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo.wv[\"image\"]  # Vector de la palabra \"image\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "f567d59b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector de la pregunta: [ 0.0021417   0.01739228  0.01566267  0.01314747 -0.01113332  0.01685121\n",
      "  0.0112926   0.01621915 -0.00301806  0.00570141  0.01263748 -0.00638959\n",
      "  0.01184658  0.00390362  0.01566871 -0.00571403 -0.00468942  0.00976107\n",
      " -0.0162175  -0.0129274  -0.01059293 -0.00200072 -0.0036456   0.01198017\n",
      "  0.01575762 -0.00148535  0.00170695  0.00372894 -0.00374415 -0.01374721\n",
      "  0.01275316 -0.00803406  0.00828245  0.01545073  0.00651095  0.00652246\n",
      "  0.00598794 -0.00561134  0.00502371  0.00062585  0.00931662  0.00946036\n",
      "  0.00271805  0.00964665 -0.01507252  0.01099488  0.0152591  -0.00699815\n",
      "  0.0021947  -0.00750969  0.00197478  0.00458855  0.01390576  0.0018398\n",
      "  0.00507629  0.00291774  0.0141964  -0.00994971 -0.00955671 -0.00731092]\n"
     ]
    }
   ],
   "source": [
    "new_tokens = simple_preprocess(QUESTION, deacc=True)\n",
    "filtered_tokens = [w for w in new_tokens if w not in stop_words and len(w) > 2]\n",
    "\n",
    "def sentence_vector(model, sentence_tokens):\n",
    "    vectors = [model.wv[word] for word in sentence_tokens if word in model.wv] # Obtener vectores de palabras conocidas\n",
    "    if vectors:\n",
    "        return np.mean(vectors, axis=0)\n",
    "    else:\n",
    "        return np.zeros(model.vector_size)\n",
    "\n",
    "# Encode\n",
    "vec1 = sentence_vector(modelo, filtered_tokens)\n",
    "\n",
    "print(\"Vector de la pregunta:\", vec1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "29bed45a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texto 0\n",
      "Similitud: 0.1537\n",
      "Texto 1\n",
      "Similitud: 0.2761\n",
      "Texto 2\n",
      "Similitud: 0.2377\n",
      "Texto 3\n",
      "Similitud: 0.2420\n",
      "Texto 4\n",
      "Similitud: 0.0918\n",
      "Texto 5\n",
      "Similitud: 0.2086\n",
      "Texto 6\n",
      "Similitud: -0.1296\n",
      "Texto 7\n",
      "Similitud: 0.2112\n",
      "Texto 8\n",
      "Similitud: 0.3411\n",
      "Texto 9\n",
      "Similitud: 0.1284\n",
      "Texto 10\n",
      "Similitud: 0.7303\n",
      "Texto 11\n",
      "Similitud: 0.5464\n",
      "Texto 12\n",
      "Similitud: nan\n",
      "Texto 13\n",
      "Similitud: 0.0892\n",
      "Texto 14\n",
      "Similitud: 0.1493\n",
      "Texto 15\n",
      "Similitud: -0.1867\n",
      "Texto 16\n",
      "Similitud: 0.0973\n",
      "Texto 17\n",
      "Similitud: 0.1919\n",
      "Texto 18\n",
      "Similitud: 0.1655\n",
      "Texto 19\n",
      "Similitud: 0.1821\n",
      "Texto 20\n",
      "Similitud: 0.1829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1087/3180159885.py:8: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  similarity = np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))\n"
     ]
    }
   ],
   "source": [
    "similarities = {}\n",
    "for i in range(len(texts)):\n",
    "    print(f\"Texto {i}\")\n",
    "    text_tokens = [w for w in simple_preprocess(texts[i], deacc=True) if w not in stop_words and len(w) > 2]\n",
    "    vec2 = sentence_vector(modelo, text_tokens)\n",
    "\n",
    "    # Compute cosine similarity\n",
    "    similarity = np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))\n",
    "    similarities[i] = similarity\n",
    "\n",
    "    print(f\"Similitud: {similarity.item():.4f}\")\n",
    "\n",
    "best_candidates =  [i[0] for i in sorted(similarities.items(), key=lambda item: item[1], reverse=True)[:5]]\n",
    "word2_vec_context = [texts[i] for i in best_candidates]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "5e4dbcb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- <!-- image -->\n",
      "\n",
      "## Evaluación\n",
      "- | Componente                     | Tipo        | Descripción                                                                                                                                                                                                                                                               | Porcentaje en la evaluación                                  |\n",
      "- - -Revisar la guía básica de Markdown para preparar el README.md con mejor estructura. https://markdown.es/\n",
      "- -Agregar  excepciones  adicionales  para  archivos  que  estemos  manejando. https://docs.github.com/es/get-started/git-basics/ignoring-files\n",
      "- -Usar. gitkeep en carpetas provisionales del proyecto (data, tmp, etc).\n",
      "- - -Conocimiento  teórico  de  algoritmos  populares  y  avanzados  de  Machine Learning en la industria\n",
      "- -Administración de ciclo de vida de modelos de Machine Learning\n",
      "1.  README.md\n",
      "- a.  Problema de ML\n",
      "- b.  Diagrama de flujo del proyecto\n",
      "- c. Descripción del dataset con su respectivo diccionario de datos\n",
      "- d.  Model Card https://www.kaggle.com/code/var0101/model-cards\n",
      "- e.  Resultados con Métricas de evaluación offline y online\n",
      "- f. Conclusiones\n",
      "- - a.  Se espera de los experimentos tener métricas , parámetros y artefactos en ellos.\n",
      "4.  Release de la versión 1.0.0** con sus respectivas notas https://docs.github.com/es/repositories/releasing-projects-on-github/managing -releases-in-a-repository\n",
      "5.  Ramas Main y Development (al menos una pull request cerrada exitosamente)\n",
      "6.  Documentación sobre la estrategia de git utilizada\n",
      "7.  [OPCIONAL] Otros (.gitignore, requirements.txt, instrucciones de ejecución )\n"
     ]
    }
   ],
   "source": [
    "for sentence in word2_vec_context:\n",
    "    print(f\"- {sentence}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8143991",
   "metadata": {},
   "source": [
    "### Sentence Transformers Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "e93abb6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 17:47:56,126 - INFO - Use pytorch device_name: cpu\n",
      "2025-10-22 17:47:56,134 - INFO - Load pretrained SentenceTransformer: hiiamsid/sentence_similarity_spanish_es\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "model = SentenceTransformer('hiiamsid/sentence_similarity_spanish_es')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "ad3105c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texto 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  5.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similitud: 0.1939\n",
      "Texto 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  3.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similitud: 0.2270\n",
      "Texto 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  3.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similitud: 0.1008\n",
      "Texto 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  3.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similitud: 0.2102\n",
      "Texto 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  8.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similitud: 0.1113\n",
      "Texto 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  4.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similitud: 0.2160\n",
      "Texto 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 19.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similitud: 0.2375\n",
      "Texto 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  5.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similitud: 0.2246\n",
      "Texto 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  5.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similitud: 0.0684\n",
      "Texto 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  7.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similitud: 0.0846\n",
      "Texto 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 18.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similitud: 0.2871\n",
      "Texto 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 17.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similitud: 0.0879\n",
      "Texto 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similitud: 0.1188\n",
      "Texto 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 12.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similitud: 0.2514\n",
      "Texto 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  8.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similitud: 0.4072\n",
      "Texto 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 11.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similitud: 0.2856\n",
      "Texto 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  9.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similitud: 0.1048\n",
      "Texto 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  8.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similitud: 0.3881\n",
      "Texto 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  8.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similitud: 0.1330\n",
      "Texto 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  5.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similitud: 0.1260\n",
      "Texto 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 10.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similitud: 0.1418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "embedding1 = model.encode(QUESTION, convert_to_tensor=True)\n",
    "\n",
    "similarities = {}\n",
    "for i in range(len(texts)):\n",
    "    print(f\"Texto {i}\")\n",
    "    embedding2 = model.encode(texts[i], convert_to_tensor=True)\n",
    "\n",
    "    # Compute cosine similarity\n",
    "    similarity = util.pytorch_cos_sim(embedding1, embedding2)\n",
    "    similarities[i] = similarity.item()\n",
    "\n",
    "    print(f\"Similitud: {similarity.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "49f7e929",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-3.3596e-01,  3.5151e-01,  1.5943e-01, -1.0919e+00,  5.6617e-02,\n",
       "         6.5108e-01,  3.5689e-01, -3.2635e-01, -7.7893e-01,  7.8155e-01,\n",
       "        -3.4961e-01, -8.8840e-02,  1.1152e-01, -4.7087e-01, -6.0106e-01,\n",
       "        -1.1122e+00,  6.8781e-01, -8.2182e-02, -4.2655e-01, -7.6112e-01,\n",
       "        -7.1291e-01, -8.9418e-01,  1.3327e+00,  1.0333e+00, -6.0296e-02,\n",
       "        -2.5595e-01,  5.8809e-01,  4.9520e-01, -7.5380e-02,  1.1351e-01,\n",
       "         6.8744e-01, -9.0994e-01,  8.9935e-01, -8.9519e-01,  4.0033e-01,\n",
       "         5.8460e-01,  6.8219e-01, -5.7879e-01, -3.9665e-01,  8.0582e-01,\n",
       "        -4.0264e-01,  4.9516e-01, -6.2085e-02,  2.1411e+00, -3.9417e-01,\n",
       "         1.0503e+00,  5.1220e-01, -5.4658e-02,  4.2341e-01,  3.6144e-01,\n",
       "        -1.1417e+00, -2.4956e-01,  3.6718e-01,  1.7407e-01, -7.2121e-02,\n",
       "        -8.2703e-01,  8.1673e-01,  1.1948e+00,  3.6988e-02,  6.6886e-01,\n",
       "        -3.0125e-01,  1.3759e+00, -9.2062e-02,  4.2017e-01,  3.7630e-01,\n",
       "        -4.7959e-01, -3.7643e-01,  2.0472e-01, -6.7676e-01,  1.1219e-01,\n",
       "         1.3570e-01, -6.2554e-01, -3.4360e-01, -5.9680e-01, -4.8969e-01,\n",
       "         2.3109e-01, -5.9597e-01, -2.2736e-01,  2.5776e-01,  6.1589e-01,\n",
       "        -9.0684e-01, -3.6625e-01,  2.2106e-02,  1.0914e+00,  4.7823e-01,\n",
       "        -1.0236e+00,  3.8126e-01, -9.4809e-01, -7.6074e-02, -5.6191e-02,\n",
       "        -2.9550e-01,  2.0178e-01,  7.2642e-01,  1.1309e+00,  7.2373e-01,\n",
       "         1.7999e+00,  5.8731e-02, -5.0125e-01, -1.1820e+00,  9.7968e-01,\n",
       "        -2.2214e-02, -9.8154e-01,  3.3002e-01,  3.4043e-02,  9.1319e-01,\n",
       "         8.9831e-01,  1.0193e+00,  1.8436e+00,  6.0858e-01,  4.1454e-01,\n",
       "         6.1539e-01,  3.8242e-01,  4.6180e-01, -8.0002e-01, -5.1401e-01,\n",
       "         4.2231e-01, -4.6745e-01, -5.2417e-01, -1.7016e+00, -4.3568e-02,\n",
       "         2.5550e-01,  3.3156e-01,  1.4469e-01,  1.8982e-01,  2.1868e+00,\n",
       "        -2.9531e-01, -1.0459e-01,  4.2195e-02, -1.3041e+00,  9.1421e-02,\n",
       "        -7.4401e-01,  1.0292e+00, -4.9091e-01,  9.4879e-01, -1.5108e-01,\n",
       "        -4.3147e-01, -1.4249e+00,  3.0660e-01, -2.0961e-01, -6.8601e-01,\n",
       "        -2.2905e-01,  9.9200e-02,  7.5853e-01,  2.4703e-01, -1.0056e-02,\n",
       "         3.6451e-02, -9.5576e-01, -3.8012e-01,  6.3047e-01, -5.6021e-02,\n",
       "         2.8438e-01, -7.9824e-01,  4.5088e-01,  9.9632e-01, -9.8393e-01,\n",
       "        -3.2225e-02, -4.1844e-01,  6.4140e-01, -5.1266e-01, -5.1600e-02,\n",
       "         4.4733e-01,  2.8956e-01, -9.7917e-01, -5.6204e-01, -3.4439e-01,\n",
       "        -9.5776e-01,  2.7301e-01,  7.4550e-01, -1.2322e+00, -3.2625e-01,\n",
       "        -7.7374e-01,  3.4770e-01, -6.5031e-01,  6.2644e-01, -6.2085e-01,\n",
       "        -3.1882e-01, -2.6758e-02, -5.9114e-02, -4.9542e-01, -8.3609e-01,\n",
       "         4.2604e-01, -5.3990e-01, -1.3704e-03, -7.6804e-02, -8.6868e-01,\n",
       "        -8.1277e-01,  3.6450e-01, -1.0749e+00,  8.7055e-01, -1.0727e+00,\n",
       "        -6.3516e-01,  4.4697e-01, -5.4192e-01,  7.5375e-01, -6.0683e-01,\n",
       "         3.7468e-01, -1.6503e+00, -2.0969e-02, -9.7316e-04, -1.9130e-02,\n",
       "         6.7075e-01,  3.7549e-01,  1.9038e+00,  3.3389e-02, -6.3237e-01,\n",
       "        -2.5012e-01, -8.2739e-01,  1.8322e-01,  4.9976e-01, -1.1235e+00,\n",
       "        -1.1591e+00, -3.4786e-01, -1.4619e-01,  1.1574e-01, -4.8820e-01,\n",
       "        -2.1517e+00, -8.5850e-01,  6.9371e-01,  1.2940e+00, -1.1791e+00,\n",
       "         4.2134e-01, -6.3243e-01, -4.3530e-01, -5.8408e-01,  2.4214e-01,\n",
       "         8.1185e-01, -3.2984e-02, -3.4774e-01, -6.6903e-03, -3.6506e-01,\n",
       "         4.0641e-01, -2.4985e-01, -7.0429e-01,  1.1594e+00, -5.8018e-01,\n",
       "         1.3080e+00,  4.0632e-01, -1.0623e+00, -5.5836e-02,  1.4713e-02,\n",
       "        -9.2841e-01,  1.1817e-01, -1.1693e+00,  7.1617e-02,  3.2855e-01,\n",
       "        -8.0192e-01,  5.2297e-01,  8.9931e-01, -1.5852e-02,  1.7138e-01,\n",
       "         1.1158e+00,  3.9558e-01,  7.4406e-01,  1.4545e-01, -6.9995e-01,\n",
       "        -8.2839e-01, -8.8763e-01, -8.5119e-02,  2.4065e-01,  5.1646e-01,\n",
       "         2.6022e-01, -9.1658e-01, -4.7838e-01, -1.9379e-02, -5.9067e-01,\n",
       "         3.9697e-01, -4.6486e-01,  6.1809e-01, -2.3050e-01, -4.9698e-01,\n",
       "         2.7488e-01, -6.7207e-01, -3.8779e-01, -3.1949e-01,  4.0728e-01,\n",
       "        -6.3867e-01,  7.2120e-01, -5.0919e-01,  9.0262e-01, -8.1458e-01,\n",
       "        -1.5282e+00,  2.3548e-01,  1.5618e-03, -2.6508e-01,  9.4248e-02,\n",
       "         8.4619e-01, -1.0483e+00, -3.2443e-01, -3.4148e-01, -5.5436e-01,\n",
       "        -9.5640e-01,  1.1431e+00,  1.3000e+00, -1.2005e+00, -2.8499e-01,\n",
       "        -9.1695e-01, -7.2343e-02,  2.8020e-01,  7.5140e-01,  3.1326e-01,\n",
       "         2.3262e-01,  5.5164e-01,  1.9058e+00,  1.8159e-01, -7.0341e-01,\n",
       "        -5.4379e-01,  7.6220e-01, -4.0179e-01,  1.8875e-01,  3.3499e-01,\n",
       "         4.9190e-01,  1.1392e+00,  5.1215e-01, -5.5388e-01, -9.2632e-01,\n",
       "        -4.5895e-01,  1.4473e+00,  1.8855e-01, -1.3164e+00, -3.0146e-01,\n",
       "         1.3202e+00,  4.4133e-01,  5.3849e-01,  5.5858e-01, -1.2867e-01,\n",
       "         8.1902e-01, -9.1798e-02, -1.0788e+00,  2.0329e+00,  8.6382e-01,\n",
       "        -1.4933e+00, -2.9975e-03, -1.3940e-01, -3.0737e-02, -1.4595e-01,\n",
       "         3.6497e-01, -2.5726e-01, -4.1563e-01, -1.3248e-01, -9.6569e-01,\n",
       "        -4.4038e-01,  9.9037e-01, -5.5042e-01, -2.7242e-01,  2.5095e-01,\n",
       "        -1.5237e-01, -2.8394e-01, -9.3816e-01, -1.4227e-01,  1.3004e-01,\n",
       "         4.8585e-01, -4.1351e-01, -3.3975e-01,  9.2782e-02,  1.4685e-01,\n",
       "        -2.2534e-01,  2.0435e-01, -7.8265e-01,  5.0839e-01, -5.3122e-01,\n",
       "        -8.9840e-01,  4.3072e-01, -1.6132e+00, -2.4245e-01, -1.0024e+00,\n",
       "         6.6710e-01, -3.7887e-01,  3.6048e-01, -7.6074e-01, -3.5535e-01,\n",
       "        -4.1647e-01,  6.7301e-01, -7.8836e-01, -4.5066e-01, -3.8727e-01,\n",
       "        -1.3544e+00, -3.8303e-01,  2.7560e-03, -8.0274e-01,  1.1234e+00,\n",
       "        -3.1869e-01, -8.7070e-01, -3.1762e-01, -1.5499e+00,  5.1048e-01,\n",
       "         4.4340e-01, -7.3147e-01,  4.7222e-01,  7.7487e-01, -1.1449e-01,\n",
       "        -5.3106e-01, -2.3041e-01,  1.3734e+00, -4.1976e-01,  5.7981e-01,\n",
       "        -1.2925e+00,  7.8307e-01, -1.6999e+00, -7.1557e-01, -4.8098e-02,\n",
       "         3.3841e-01, -4.8444e-01, -6.0738e-02,  5.4057e-01, -6.4545e-01,\n",
       "         1.7620e-01, -3.7743e-02, -6.1088e-01,  2.1819e-01,  9.8226e-01,\n",
       "        -1.8591e-01, -7.6110e-02,  7.3035e-01, -1.3440e-01, -1.8217e+00,\n",
       "        -2.2734e-02,  1.1358e+00,  4.7750e-01, -9.4686e-02, -7.7244e-01,\n",
       "        -7.8383e-01,  8.6016e-01,  7.9984e-01,  5.9019e-01, -5.6983e-01,\n",
       "         2.2940e-02, -3.9276e-01, -2.2258e-01,  9.3446e-01, -4.9643e-01,\n",
       "        -5.7686e-01,  4.3193e-01,  1.2828e+00, -7.7645e-01,  2.2681e-01,\n",
       "        -4.2747e-01, -3.0401e-01, -4.9274e-01,  1.7306e-02,  1.5951e-01,\n",
       "        -9.6949e-01, -6.1187e-01, -5.2137e-01, -6.3685e-01,  1.0813e+00,\n",
       "        -1.0018e+00,  4.9991e-01, -1.4549e+00,  6.8782e-02,  4.6093e-01,\n",
       "         5.3316e-02,  7.9613e-02,  3.2568e-01, -4.7294e-01, -9.0010e-01,\n",
       "        -3.4180e-02, -6.0124e-03, -1.8594e-01, -5.4965e-01,  1.4709e-02,\n",
       "        -2.1202e-01,  2.5945e-01,  4.4581e-02, -7.0000e-01, -7.1931e-01,\n",
       "        -1.7753e-01, -1.2053e+00,  1.6385e-01, -2.7805e-01,  1.2552e-01,\n",
       "        -2.2263e-01, -4.4572e-02,  1.5290e+00, -4.6333e-01, -5.5971e-02,\n",
       "         1.0014e+00,  1.8012e+00,  2.3100e-01,  1.0079e+00, -3.0335e-01,\n",
       "         1.5236e-01,  9.0723e-02, -6.2796e-01,  3.7427e-01, -9.1154e-01,\n",
       "         2.4913e-01,  3.4108e-01, -4.2790e-01, -6.4322e-01, -8.6248e-02,\n",
       "        -3.8074e-01,  3.0932e-01, -4.9904e-01,  1.3714e-01, -6.1666e-01,\n",
       "        -3.1348e-01, -8.0554e-01, -1.1898e+00,  5.7494e-01,  7.6273e-01,\n",
       "         2.8717e-01, -4.1947e-02, -5.6957e-01, -3.3832e-01,  2.9867e-01,\n",
       "        -7.9152e-02,  2.0229e-02, -4.8280e-01, -7.0161e-01,  4.3717e-01,\n",
       "        -6.3728e-01,  1.4458e-03,  1.0206e+00,  3.1084e-01,  4.4961e-01,\n",
       "         3.6149e-01,  3.3144e-01, -1.5908e-01,  9.8571e-02, -1.1414e-01,\n",
       "        -6.1566e-01,  1.0853e+00, -1.2726e-01,  2.4894e-02,  5.8513e-01,\n",
       "         3.0995e-02,  1.8923e+00, -2.7598e-01, -1.3637e-01,  6.6614e-01,\n",
       "         2.7706e-01, -9.6556e-01,  2.2934e-01,  8.9674e-02, -9.3634e-01,\n",
       "        -2.9484e-01,  3.1576e-01, -1.0745e-01, -1.2212e+00, -4.6960e-01,\n",
       "         3.3425e-01, -4.0206e-01,  1.0154e-01, -3.4013e-01, -5.7009e-02,\n",
       "         8.1717e-01,  4.4516e-01,  1.0559e+00, -3.2163e-01,  5.9180e-01,\n",
       "        -5.3756e-01,  5.1994e-01, -9.2981e-02,  9.2685e-02,  1.3106e-01,\n",
       "        -1.7789e-01, -2.3912e-01, -9.8777e-02,  6.0977e-01,  2.6752e-01,\n",
       "        -3.7179e-01,  1.3215e+00,  9.4260e-02, -2.3964e-01,  6.1627e-01,\n",
       "         8.3519e-01, -1.0637e+00,  2.6174e-02, -4.6223e-01,  1.3042e+00,\n",
       "        -4.4737e-01, -1.1557e+00,  5.4411e-01, -5.7468e-01, -9.6333e-01,\n",
       "        -4.4644e-01,  1.5846e-01,  1.0141e-01,  5.7621e-01,  5.5815e-02,\n",
       "        -6.7756e-01, -1.1690e+00, -1.6694e-01, -1.0405e-02,  1.0394e+00,\n",
       "        -6.0997e-01,  8.7534e-02, -6.3288e-01, -5.1036e-01,  7.9843e-04,\n",
       "        -6.6556e-01, -1.0513e-01,  5.1905e-01, -1.4865e+00, -2.9116e-01,\n",
       "         1.6015e+00,  4.8893e-01,  5.7258e-01, -5.8428e-01, -1.9919e-01,\n",
       "         1.0688e+00, -2.5810e-01,  1.1004e+00,  6.0671e-01, -9.1199e-01,\n",
       "        -6.4973e-01,  9.5091e-01,  2.9138e-01,  4.7773e-01,  8.0457e-01,\n",
       "         3.1261e-01, -3.0760e-01,  2.2787e-01, -2.8768e-01,  5.2388e-01,\n",
       "         8.7552e-01,  1.5329e+00,  1.6161e-01, -5.3366e-01, -1.4621e+00,\n",
       "         2.6335e-01, -8.3941e-01, -8.7399e-02,  5.5644e-01, -7.3321e-01,\n",
       "        -7.4623e-01,  4.6894e-01,  9.7266e-02, -8.1219e-01,  7.7247e-01,\n",
       "        -5.9592e-01,  3.3328e-01,  2.0258e-01,  3.0489e-01,  3.4521e-01,\n",
       "        -1.7463e-01, -1.4562e-01,  2.6838e-01, -5.9130e-01, -1.6517e+00,\n",
       "         1.4100e+00, -9.7633e-01,  4.8079e-01, -5.9296e-02,  2.4302e-01,\n",
       "         8.3543e-01,  2.8760e-01, -4.4530e-01, -6.9340e-01,  9.0630e-01,\n",
       "         1.5196e-01,  8.3084e-01, -3.1330e-01,  9.0416e-01, -4.7806e-01,\n",
       "        -8.1773e-01,  9.9370e-01, -4.0516e-01, -5.8949e-01, -4.4029e-01,\n",
       "         8.1804e-01,  1.3972e-01, -7.4942e-01,  2.7569e-01,  2.6549e-01,\n",
       "        -3.0458e-01,  5.9189e-01,  4.1771e-01, -1.4550e-01,  7.5343e-02,\n",
       "        -1.0421e+00,  4.6193e-01, -1.0887e-01,  4.6602e-01, -1.0255e+00,\n",
       "        -5.2310e-01, -1.2089e+00, -5.3333e-01, -2.5434e-01, -9.8183e-01,\n",
       "        -4.0621e-02,  3.2304e-01, -5.0509e-01,  1.4258e-01,  9.0733e-01,\n",
       "         3.7125e-01, -1.1440e+00, -3.4917e-01, -1.3732e-01,  1.3158e+00,\n",
       "         4.6370e-01,  1.3255e+00, -1.2536e-01,  3.1993e-01,  6.1426e-01,\n",
       "         2.8045e-01, -1.2817e+00, -6.7909e-01, -5.6159e-01, -1.6619e+00,\n",
       "        -8.1552e-01, -6.5940e-01,  1.2393e-01, -8.9134e-01,  4.7684e-01,\n",
       "        -3.8148e-01,  5.6759e-01, -7.6244e-01, -2.4653e-01, -8.6501e-01,\n",
       "         2.8953e-01,  5.8240e-01,  6.8636e-01, -3.7319e-03, -1.8324e-01,\n",
       "         6.9246e-01,  5.7118e-03,  3.2549e-01, -6.0632e-01, -1.4938e-01,\n",
       "        -8.8501e-01, -6.5125e-01,  1.7270e-01,  3.9535e-01,  1.8572e+00,\n",
       "         1.9608e+00, -8.6796e-01, -6.7132e-01, -6.6194e-01,  7.1127e-01,\n",
       "        -1.3042e-01,  5.3731e-01, -5.8761e-01, -1.3141e+00,  6.4315e-01,\n",
       "        -3.0724e-01, -1.4603e-01,  1.0843e+00, -3.1764e-01,  2.5440e-01,\n",
       "        -3.9519e-01,  3.2905e-01,  1.2895e+00, -1.4943e-01,  7.2623e-01,\n",
       "        -5.0730e-01, -4.0367e-02,  4.8151e-01,  2.6478e-01,  5.7523e-01,\n",
       "        -1.4818e+00, -5.0252e-01, -4.1784e-01,  9.3080e-01,  1.5646e-01,\n",
       "        -1.4860e-01,  2.0547e-01, -5.9124e-01,  3.9607e-01, -6.3023e-01,\n",
       "         3.3362e-01,  3.6078e-01, -5.0432e-01, -3.0849e-01,  4.6991e-01,\n",
       "        -1.0357e+00,  7.4601e-01,  1.5933e-01])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "dcdc893c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['| Modelo de Machine Learning     | Obligatorio | El estudiante documenta y desarrolla un modelo de machine learning alineado con sus hipótesis, además de evaluarlo con métricas que tengan sentido para el problema que previamente escogió y usando mlflow como herramienta de administración de modelos y experimentos. | 50%                                                          |',\n",
       " '| Reto ML 1                      | Opcional    | El estudiante demuestra dominio de los algoritmos vistos en clase realizando experimentos con más de uno y obteniendo resultados excepcionales (estos dependerán e tipo de problema que se busque resolver)                                                               | 10% [Acumulable para todos los cursos de la especialización] |',\n",
       " '<!-- image -->\\n\\n## Evaluación',\n",
       " '| Buenas prácticas de desarrollo | Obligatorio | El estudiante sigue el proceso estándar de desarrollo basado en control de versiones, usando commits, pull requests y releases en su proyecto.                                                                                                                            | 15%                                                          |',\n",
       " '| Repositorio de Github          | Obligatorio | El estudiante presenta su proyecto de acuerdo con la estructura definida por el profesor.                                                                                                                                                                                 | 25%                                                          |']"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_candidates =  [i[0] for i in sorted(similarities.items(), key=lambda item: item[1], reverse=True)[:5]]\n",
    "hf_context = [texts[i] for i in best_candidates]\n",
    "hf_context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce9ef25",
   "metadata": {},
   "source": [
    "### Embeddings with Gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "a5b1e271",
   "metadata": {},
   "outputs": [],
   "source": [
    "genai.configure(api_key=os.getenv(\"GOOGLE_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "0b8a2487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Contexto más relevante encontrado por Gemini ---\n",
      "['<!-- image -->\\n\\n## Evaluación', '| Componente                     | Tipo        | Descripción                                                                                                                                                                                                                                                               | Porcentaje en la evaluación                                  |', '| Repositorio de Github          | Obligatorio | El estudiante presenta su proyecto de acuerdo con la estructura definida por el profesor.                                                                                                                                                                                 | 25%                                                          |', '| Buenas prácticas de desarrollo | Obligatorio | El estudiante sigue el proceso estándar de desarrollo basado en control de versiones, usando commits, pull requests y releases en su proyecto.                                                                                                                            | 15%                                                          |', '## Sugerencias para el proyecto']\n"
     ]
    }
   ],
   "source": [
    "# 1. Crea el embedding para la pregunta (esto sigue siendo una sola llamada)\n",
    "response_q = genai.embed_content(\n",
    "    model=\"gemini-embedding-001\",\n",
    "    content=QUESTION\n",
    ")\n",
    "\n",
    "vec1 = response_q['embedding']\n",
    "\n",
    "response_chunks = genai.embed_content(\n",
    "    model=\"gemini-embedding-001\",\n",
    "    content=texts  # <-- ¡Le pasas la lista completa de textos aquí!\n",
    ")\n",
    "\n",
    "all_vec2 = response_chunks['embedding']\n",
    "\n",
    "# 3. Calcula la similitud del coseno (ahora es más fácil con NumPy)\n",
    "#    No necesitas un bucle. Puedes hacerlo todo con operaciones de vectores.\n",
    "similarities = np.dot(all_vec2, vec1) / (np.linalg.norm(all_vec2, axis=1) * np.linalg.norm(vec1))\n",
    "\n",
    "\n",
    "# 4. Encuentra los mejores candidatos (más directo)\n",
    "#    np.argsort() te da los índices de los valores ordenados.\n",
    "best_candidates_indices = np.argsort(similarities)[::-1][:5] # Ordena de mayor a menor y toma los 5 primeros\n",
    "\n",
    "gemini_context = [texts[i] for i in best_candidates_indices]\n",
    "\n",
    "print(\"\\n--- Contexto más relevante encontrado por Gemini ---\")\n",
    "print(gemini_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "f48ffe2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similitud: 0.5765\n",
      "Similitud: 0.5566\n",
      "Similitud: 0.6088\n",
      "Similitud: 0.6113\n",
      "Similitud: 0.6097\n",
      "Similitud: 0.5580\n",
      "Similitud: 0.6208\n",
      "Similitud: 0.6064\n",
      "Similitud: 0.5494\n",
      "Similitud: 0.5204\n",
      "Similitud: 0.7413\n",
      "Similitud: 0.7399\n",
      "Similitud: 0.5255\n",
      "Similitud: 0.6465\n",
      "Similitud: 0.6262\n",
      "Similitud: 0.6245\n",
      "Similitud: 0.6061\n",
      "Similitud: 0.6130\n",
      "Similitud: 0.5330\n",
      "Similitud: 0.5934\n",
      "Similitud: 0.5309\n"
     ]
    }
   ],
   "source": [
    "response_q = genai.embed_content(\n",
    "    model=\"gemini-embedding-001\",\n",
    "    content=QUESTION,\n",
    "    output_dimensionality= 768 \n",
    ")\n",
    "vec1 = response_q['embedding'] # El vector está en la clave 'embedding'\n",
    "\n",
    "# 2. Bucle para comparar con cada chunk de texto\n",
    "similarities = {}\n",
    "for i in range(len(texts)):\n",
    "    \n",
    "    # Crea el embedding para el chunk actual\n",
    "    response_chunk = genai.embed_content(\n",
    "        model=\"gemini-embedding-001\",\n",
    "        content=texts[i],\n",
    "        output_dimensionality= 768\n",
    "        \n",
    "    )\n",
    "    vec2 = response_chunk['embedding']\n",
    "    \n",
    "    # 3. El cálculo de similitud del coseno NO CAMBIA\n",
    "    similarity = np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))\n",
    "    similarities[i] = similarity\n",
    "\n",
    "    print(f\"Similitud: {i} {similarity:.4f}\")\n",
    "\n",
    "# 4. La selección de los mejores candidatos TAMPOCO CAMBIA\n",
    "best_candidates = [i[0] for i in sorted(similarities.items(), key=lambda item: item[1], reverse=True)[:5]]\n",
    "gemini_context = [texts[i] for i in best_candidates]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "44acd167",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inicio de chunk\n",
      "- <!-- image -->\n",
      "\n",
      "## Evaluación\n",
      "--------------------\n",
      "Inicio de chunk\n",
      "- | Componente                     | Tipo        | Descripción                                                                                                                                                                                                                                                               | Porcentaje en la evaluación                                  |\n",
      "--------------------\n",
      "Inicio de chunk\n",
      "- | Repositorio de Github          | Obligatorio | El estudiante presenta su proyecto de acuerdo con la estructura definida por el profesor.                                                                                                                                                                                 | 25%                                                          |\n",
      "--------------------\n",
      "Inicio de chunk\n",
      "- | Modelo de Machine Learning     | Obligatorio | El estudiante documenta y desarrolla un modelo de machine learning alineado con sus hipótesis, además de evaluarlo con métricas que tengan sentido para el problema que previamente escogió y usando mlflow como herramienta de administración de modelos y experimentos. | 50%                                                          |\n",
      "--------------------\n",
      "Inicio de chunk\n",
      "- | Buenas prácticas de desarrollo | Obligatorio | El estudiante sigue el proceso estándar de desarrollo basado en control de versiones, usando commits, pull requests y releases en su proyecto.                                                                                                                            | 15%                                                          |\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "for sentence in gemini_context:\n",
    "    print(\"Inicio de chunk\")\n",
    "    print(f\"- {sentence}\", sep=\"\\n\")\n",
    "    print(\"-\"*20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef9c52bf",
   "metadata": {},
   "source": [
    "## Construcción Final RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0c62b6",
   "metadata": {},
   "source": [
    "### GEMINI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aafc37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uv add google-generativeai\n",
    "import os\n",
    "import google.generativeai as genai\n",
    "\n",
    "genai.configure(api_key=os.getenv(\"GOOGLE_API_KEY\"))\n",
    "\n",
    "\n",
    "PROMPT = f\"\"\"Responde a la siguiente pregunta dado un CONTEXTO que contiene información para responder esa pregunta:\n",
    "\n",
    "PREGUNTA\n",
    "-------------------\n",
    "{QUESTION}\n",
    "\n",
    "CONTEXTO:\n",
    "{''.join(gemini_context)}\n",
    "---------------------\n",
    "\n",
    "Crea el resultado final como un texto plano con formato markdown que pueda ser renderizado (evita incluir ```markdown como apertura)\"\"\"\n",
    "\n",
    "model = genai.GenerativeModel(\"gemini-2.5-flash\") # gemini-2.5-pro\n",
    "\n",
    "# 2. Envía el prompt al modelo para generar la respuesta\n",
    "response = model.generate_content(PROMPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "c45ad71e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Los criterios de evaluación son los siguientes:\n",
       "\n",
       "*   **Repositorio de Github (25%):** El estudiante presenta su proyecto de acuerdo con la estructura definida por el profesor.\n",
       "*   **Modelo de Machine Learning (50%):** El estudiante documenta y desarrolla un modelo de machine learning alineado con sus hipótesis, lo evalúa con métricas pertinentes al problema y usa mlflow como herramienta de administración.\n",
       "*   **Buenas prácticas de desarrollo (15%):** El estudiante sigue el proceso estándar de desarrollo basado en control de versiones, usando commits, pull requests y releases en su proyecto."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(\n",
    "    Markdown(response.text)  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "8142c0f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Los criterios de evaluación son los siguientes:\n",
       "\n",
       "*   **Modelo de Machine Learning (Obligatorio):** El estudiante documenta y desarrolla un modelo de machine learning alineado con sus hipótesis, además de evaluarlo con métricas que tengan sentido para el problema que previamente escogió y usando mlflow como herramienta de administración de modelos y experimentos. (50%)\n",
       "*   **Reto ML 1 (Opcional):** El estudiante demuestra dominio de los algoritmos vistos en clase realizando experimentos con más de uno y obteniendo resultados excepcionales (estos dependerán del tipo de problema que se busque resolver). (10% [Acumulable para todos los cursos de la especialización])\n",
       "*   **Buenas prácticas de desarrollo (Obligatorio):** El estudiante sigue el proceso estándar de desarrollo basado en control de versiones, usando commits, pull requests y releases en su proyecto. (15%)\n",
       "*   **Repositorio de Github (Obligatorio):** El estudiante presenta su proyecto de acuerdo con la estructura definida por el profesor. (25%)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(\n",
    "    Markdown(response.text)\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml2-clases",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
